{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cddf5b16-a118-4755-b585-7a380eb43800",
   "metadata": {},
   "source": [
    "# Motivation for the next few experiments\n",
    "Experment 1.1.1 found a simple way to make a dataset which captures a non-chroma based color distinction (orange vs. brown). \n",
    "The hope at the end of that experiment was that we could use this type of data to compare human and neural network color perception in a way that revealed something interesting.\n",
    "\n",
    "To make a comparison, though, we need some way of inspecting neural networks so that we can make some useful statements about them. Below are some ideas.\n",
    "\n",
    "## 1. Train a network on the circle-background dataset\n",
    "Take (or remake) the labelled dataset from experiment 1.1, and use it to train a neural network classifier. How many layers would we need? We should probably augment the dataset; however, it might be tricky to augment the dataset in a way that we can be sure that the colors experienced by the human observer do not change. I am very confident that the task is really easy and will be easily solved: the network just needs to compare background-forground brightness and check that the hue stays within a certain bounds. Brighness and hue aren't given to the network, but they are easily obtained from RGB values. If we don't augment the dataset, then the network is free to ignore most of the image and just consider a couple of pixels around the boundary of the cirle. Given these thoughts, this experiment idea doesn't seem like it will reveal much. Although, if for some very strange reason the network struggled with the problem, then that would be a very interesting find; this outcome seems extremely remote, so I don't think it makes the experiment any more appealing.\n",
    "\n",
    "## 2. Pretained model: circle-background dataset\n",
    "Take a pretrained model, for example, a Resnet model trained on ImageNet, and feed it the cirlce-background images from experiment 1.1. I'm not quite sure what this would achive. What would I look for? I don't see much use in inspecting the activations of a particular layer. A vague idea is that I'm looking for neuron's or filters that are encoding orange or brown; however, I don't think the data is sufficient as-is. One technique which might be helpful is to augment the data by moving the circle around and searching over the whole network for two channels: 1 channel that correlates to the input images, but only when the circle is orange, and another channel that correlates to the input images when the circle is brown. This correlation measure would need to deal with the differences in resolution between the input image and the different channels. The test becomes less meaningful for channels further away from the input, as the lower resolutions and effects of pooling reduce a channel's position specificity. \n",
    "\n",
    "If I manage to find channels that seem to identify areas of orange or brown, I think this provides some evidence that the neural network has both been able to and has found it useful to encode the sense of orange and brown. I think this would be an interesting statement to be able to make. From here, some further questions could be asked: can we apply channel visualization techniques to these channels to discover something interesting? Maybe the network only searches for brown/orange in certain areas of the image. What classes depend on input from the brown/orange channels?\n",
    "\n",
    "My guess, though, is that I won't find such channels. Looking at the ImageNet classes, there doesn't seem to be many object classes that are similar enough to need orange and brown to be vital to the classification. This is true for most colors it seems. If the color isn't that important, then there most likely isn't going to be a whole channel dedicated to cleanly representing a color. A counterpoint to this claim would be Goh, et al.'s work at visualizing neurons of Open AI's CLIP network⁠—they managed to find channels that had a strong connection to identifying yellow in an image, in various forms. \n",
    "\n",
    "As I think it's unlikely to find such a special channel, I also think not finding such channels doesn't really reveal any useful information. The effort to reward ratio is a bit too high to make this an appealing experiment.\n",
    "\n",
    "## 3. Pretrained model: oranges vs. lemons in ImageNet\n",
    "Inspecting the ImageNet class list reveals an exploitable opportunity: out of all the classes, the 2 class pairs (orange, lemon) and (broccoli, cauliflower) which I believe humans require color in order to classify, or in other words, I think humans could be tricked into misclassifying if the colors were to be manipulated. My photo editing skills probably are not good enough to convert a brocolli into a cauliflower; however, I think I can convert between oranges and lemons (to trick a human). \n",
    "\n",
    "Maybe the similarity of oranges and lemons will have forced Resnet trained on ImageNet to learn a representation the orange-yellow difference, and maybe this representation is nicely packaged into a channel of some layer. Playing with these classes might be a shortcut version of the experiment above: does the network require color info? If not, then there isn't really much we can do. If it does, then does it appear in a channel? \n",
    "\n",
    "Either way, this experiment should reveal something at least slightly interesting: \n",
    "- the network is somewhat yellow/orange color blind. (would we have enough evidence to use a stronger word than \"somewhat\"?), or\n",
    "- the network relies on the yellow/orange color difference to decide at least one class.\n",
    "\n",
    "## 4. Pretrained model: what about standard colors?\n",
    "What about standard colors that have an RGB value? Because the input to the vision networks is typically RGB values, a network already has a nice model for these colors. What remains to ask here is whether the network somehow subdivides this space in some way, similar to how humans divide it into red, orange, yellow etc. (compare this to audio perception where most people cannot identify, and thus name, a pitch.\n",
    "\n",
    "The target output of an experiment idea like this would be to display the 3D volume representing the typical XYZ colorimitry space and draw boundaries to show distinct color regions that are interpreted as a single \"color\" be the network.\n",
    "\n",
    "This idea seems intriguing, but I'm not quite sure how to go about it yet. Like the 2nd experiment idea above, a model trained on ImageNet probably has no need to develop such a model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e33dfe-5996-4e30-9c70-0633ed5eb60d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
